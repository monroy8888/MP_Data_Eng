"""MercadoLibre-SergioQuiroga.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V4JQ-QQalfu3M6-e9TLjFYpNEcG9mU3w

# ***MercadoPago***

**contexto**

En el contexto de MercadoPago, se quiere desarrollar un modelo de Machine Learning para
predecir el orden de un conjunto de Propuestas de Valor (aka, Value Props) en el carrusel
de la app llamado “Descubrí Más”.


***Tarea***

La tarea consiste en construir utilizando Python y sus librerías un pipeline que tenga como
input 3 fuentes de datos diferentes y genere como resultado un dataset listo para ser
ingerido por el modelo.

# ***Expected Result***

El dataset a construir deberá contar con la siguiente información:

● prints de la última semana

● por cada print:

     ○ un campo que indique si se hizo click o no

     ○ cantidad de veces que el usuario vio cada value prop en las 3 semanas previas a ese print.

     ○ cantidad de veces que el usuario clickeo cada value prop en las 3 semanas previas a ese print.

     ○ cantidad de pagos que el usuario realizó para cada value prop en las 3 semanas previas a ese print.

     ○ importes acumulados que el usuario gasto para cada value prop en las 3 semanas previas a ese print.

***Deliverables***

    ● Código Python
    ● Un Doc con una breve descripción de las decisiones tomadas.

***Extracción (Extract):***

***Transformación (Transform):***


* Limpieza de datos: eliminar datos duplicados, valores nulos inconsistencias, etc.
* Estandarización: convertir los datos en un formato uniforme y coherente.
* Normalización: estructurar los datos de manera que sigan un modelo predefinido.
* Enriquecimiento: añadir datos adicionales provenientes de otras fuentes para mejorar su calidad o contexto.
* Agregación: combinar y resumir datos para generar información más útil.
* Derivación: crear nuevos atributos o calcular métricas a partir de los datos existentes.
* Filtrado: eliminar datos no deseados o irrelevantes.



***Carga (Load):***

* En esta etapa, los datos transformados se cargan en el sistema de destino, que puede ser un almacén de datos, un data lake, una base de datos relacional, un sistema de almacenamiento en la nube, entre otros.

***Monitoreo y Mantenimiento:***

* Una vez que los datos han sido cargados en el sistema de destino, es crucial monitorear su calidad y rendimiento de manera regular.
"""

#historial de 1 mes de pagos realizados por los usuarios
pays_path = '/content/drive/MyDrive/dataSpark/CodeExercise DE - Carrusel XSelling 2/pays.csv'

#historial de 1 mes de value props que fueron mostradas a cada usuario
prints_path = '/content/drive/MyDrive/dataSpark/CodeExercise DE - Carrusel XSelling 2/prints.json'

#historial de 1 mes de value props que fueron clickeadas por un usuario
taps_path = '/content/drive/MyDrive/dataSpark/CodeExercise DE - Carrusel XSelling 2/taps.json'

!apt-get install openjdk-8-jdk-headless -qq > /dev/null
!wget -q https://archive.apache.org/dist/spark/spark-3.0.0/spark-3.0.0-bin-hadoop3.2.tgz
!tar xf spark-3.0.0-bin-hadoop3.2.tgz


import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-3.0.0-bin-hadoop3.2"


!pip install -q findspark

import findspark
findspark.init()

from pyspark.sql import SparkSession

from pyspark.sql.types import IntegerType, StringType
from pyspark.sql.functions import to_date, when, count, window, desc, asc, sum

from pyspark.sql import  SQLContext

spark = SparkSession.builder \
    .appName("MercadoPago") \
    .getOrCreate()

"""# ***paysDF***

* historial de 1 mes de pagos realizados por los usuarios
"""

paysDF = spark.read.csv(path=pays_path, header=True)

paysDF = paysDF.withColumn('pay_date', to_date(paysDF['pay_date'], 'yyyy-MM-dd'))
paysDF = paysDF.withColumn('total', paysDF['total'].cast(IntegerType()))
paysDF = paysDF.withColumn('user_id', paysDF['user_id'].cast(IntegerType()))
paysDF = paysDF.withColumn('value_prop', paysDF['value_prop'].cast(StringType()))

paysDF.printSchema()

paysDF.show()

"""# ***printsDF***

* historial de 1 mes de value props que fueron mostradas a cada usuario
"""

printsDF = spark.read.json(prints_path)
printsDF.printSchema()

printsDF = printsDF.withColumn('day_prints', to_date(printsDF['day'], 'yyyy-MM-dd'))
printsDF = printsDF.withColumn('position_prints', printsDF['event_data.position'].cast(IntegerType())) \
                           .withColumn('value_prop_prints', printsDF['event_data.value_prop'].cast(StringType()))
printsDF = printsDF.drop('event_data')
printsDF = printsDF.drop('day')
printsDF = printsDF.withColumn('user_id', printsDF['user_id'].cast(IntegerType()))

printsDF.show()

"""# ***tapsDF***

* historial de 1 mes de value props que fueron clickeadas por un usuario
"""

tapsDF = spark.read.json(taps_path)
tapsDF.printSchema()

tapsDF = tapsDF.withColumn('day_taps', to_date(tapsDF['day'], 'yyyy-MM-dd'))
tapsDF = tapsDF.withColumn('position_taps', tapsDF['event_data.position'].cast(IntegerType())) \
                           .withColumn('value_prop_taps', tapsDF['event_data.value_prop'].cast(StringType()))
tapsDF = tapsDF.drop('event_data')
tapsDF = tapsDF.drop('day')
tapsDF = tapsDF.withColumn('user_id', tapsDF['user_id'].cast(IntegerType()))

"""***Desarrollo***

> Campo que indique si se hizo click o no
"""

prints_click_DF = printsDF.withColumn('click', when(printsDF['position_prints'] != 0, True).otherwise(False))
prints_click_DF.show()

"""> Cantidad de veces que el usuario vio cada value prop en las 3 semanas previas a ese print."""

prints_view_quantity_DF = printsDF.groupBy('user_id', 'value_prop_prints', window('day_prints', '3 weeks').alias('three_weeks')).agg(count('*').alias('view_quantity'))
prints_view_quantity_DF.show()

"""> Contar la cantidad de veces que el usuario clickeó cada value prop en las 3 semanas previas"""

taps_clicks_quantity_DF = tapsDF.groupBy('user_id', 'value_prop_taps', window('day_taps', '3 weeks').alias('three_weeks')).agg(count('*').alias('clicks_quantity'))
taps_clicks_quantity_DF.show()

"""> Contar la cantidad de pagos que el usuario realizó para cada value prop en las 3 semanas previas"""

pays_count_DF = paysDF.groupBy('user_id', 'value_prop', window('pay_date', '3 weeks').alias('three_weeks')).agg(count('*').alias('pays_count'))
pays_count_DF.show()

"""> Calcular importes acumulados que el usuario gastó para cada value prop en las 3 semanas previas"""

pays_total_DF = paysDF.groupBy('user_id', 'value_prop', window('pay_date', '3 weeks').alias('three_Weeks')).agg(sum('total').alias('pays_total'))
pays_total_DF.show()